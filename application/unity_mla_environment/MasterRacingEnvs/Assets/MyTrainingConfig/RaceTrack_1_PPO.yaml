# Command to run from ~/projekty/praca_magisterska/application/unity_mla_environment:
# mlagents-learn MasterRacingEnvs/Assets/MyTrainingConfig/RaceTrack_2_PPO.yaml --run-id=RaceTrack_2_PPO --results-dir=MasterRacingEnvs/Assets/MyTrainingResults

engine_settings:
  width: 240 # default = 84
  height: 135 # default = 84
  quality_level: 5 # default = 5
  time_scale: 20 # default = 20
  target_frame_rate: -1 # default = -1
  capture_frame_rate: 60 # default = 60
  no_graphics: false
torch_settings:
  device: cuda # default = cpu
behaviors:
  CarAgentBehaviour:
    trainer_type: ppo
    summary_freq: 20000 # default = 50000
    time_horizon: 256 # default = 64, typical range: 32 - 2048
    max_steps: 5000000 # default = 500000, typical range: 5e5 - 1e7
    keep_checkpoints: 10 # default = 5
    checkpoint_interval: 500000 # default = 500000
    threaded: true # default = false
    network_settings:
      hidden_units: 128 # default = 128, typical range: 32 - 512
      num_layers: 2 # default = 2, typical range: 1 - 3
      normalize: true # default = false
      vis_encode_type: simple # default = simple, all values: simple, nature_cnn, resnet, match3, fully_connected
      conditioning_type: none # default = hyper, all values: hyper, none
    reward_signals:
      extrinsic:
        strength: 1.0 # default = 1.0
        gamma: 0.99 # default = 0.99, typical range: 0.8 - 0.995. Must be smaller than 1.

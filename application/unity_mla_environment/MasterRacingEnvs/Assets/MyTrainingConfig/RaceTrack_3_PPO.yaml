# Command to run from ~/projekty/praca_magisterska/application/unity_mla_environment:
# mlagents-learn MasterRacingEnvs/Assets/MyTrainingConfig/RaceTrack_2_PPO.yaml --run-id=RaceTrack_2_PPO --results-dir=MasterRacingEnvs/Assets/MyTrainingResults

engine_settings:
  width: 240 # default = 84
  height: 135 # default = 84
  quality_level: 5 # default = 5
  time_scale: 20 # default = 20
  target_frame_rate: -1 # default = -1
  capture_frame_rate: 60 # default = 60
  no_graphics: false
torch_settings:
  device: cuda # default = cpu
behaviors:
  CarAgentBehaviour:
    trainer_type: ppo
    summary_freq: 50000 # default = 50000
    time_horizon: 256 # default = 64, typical range: 32 - 2048
    max_steps: 30000000 # default = 500000, typical range: 5e5 - 1e7
    keep_checkpoints: 10 # default = 5
    checkpoint_interval: 500000 # default = 500000
    threaded: true # default = false
    #hyperparameters:
      ## Hyperparameters common to PPO and SAC
      #learning_rate: 0.0003 # default = 3e-4, typical range: 1e-5 - 1e-3
      #batch_size: 2816 # typical range: 512 - 5120
      #buffer_size: 28160 # default = 10240, typical range: 2048 - 409600
      #learning_rate_schedule: linear
      ## PPO-specific hyperparameters
      #beta: 0.005 # default = 5.0e-3, typical range: 1e-4 - 1e-2
      #epsilon: 0.2 # default = 0.2, typical range: 0.1 - 0.3
      #lambd: 0.95 # default = 0.95, typical range: 0.9 - 0.95
      #num_epoch: 3 # default = 3, typical range: 3 - 10
    network_settings:
      hidden_units: 128 # default = 128, typical range: 32 - 512
      num_layers: 2 # default = 2, typical range: 1 - 3
      normalize: true # default = false
      vis_encode_type: simple # default = simple, all values: simple, nature_cnn, resnet, match3, fully_connected
      conditioning_type: none # default = hyper, all values: hyper, none
    reward_signals:
      extrinsic:
        strength: 1.0 # default = 1.0
        gamma: 0.99 # default = 0.99, typical range: 0.8 - 0.995. Must be smaller than 1.
      #curiosity:
        #strength: 0.1 # default = 1.0, typical range: 0.001 - 0.1
        #gamma: 0.99 # default = 0.99, typical range: 0.8 - 0.995
        #network_settings:
          #hidden_units: 128 # default = 128, typical range: 64 - 256
          #num_layers: 2 # default = 2, typical range: 1 - 3
          #normalize: true # default = false
          #vis_encode_type: simple # default = simple, all values: simple, nature_cnn, resnet, match3, fully_connected
          #conditioning_type: none # default = hyper, all values: hyper, none
        #learning_rate: 0.0003 # default = 3e-4, typical range: 1e-5 - 1e-3
      #gail:
        #strength: 1.0 # default = 1.0, typical range: 0.01 - 1.0
        #gamma: 0.99 # default = 0.99, typical range: 0.8 - 0.9
        #demo_path: MasterRacingEnvs/Assets/MyDemonstrations/RaceTrack1Demo1.demo # Required, no default
        #network_settings:
          #hidden_units: 128 # default = 128, typical range: 64 - 256
          #num_layers: 2 # default = 2, typical range: 1 - 3
          #normalize: true # default = false
          #vis_encode_type: simple # default = simple, all values: simple, nature_cnn, resnet, match3, fully_connected
          #conditioning_type: none # default = hyper, all values: hyper, none
        #learning_rate: 0.0003 # Optional, default = 3e-4, typical range: 1e-5 - 1e-3
        #use_actions: true # default = false
        #use_vail: false # default = false
    #behavioral_cloning:
      #demo_path: MasterRacingEnvs/Assets/MyDemonstrations/RaceTrack1Demo1.demo # Required, no default
      #strength: 0.5 # default = 1.0, typical range: 0.1 - 0.5
      #steps: 0 # default = 0
